{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, sentiment = [], []\n",
    "with open(\"./movie review/train.tsv\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i > 0:\n",
    "            line = line.strip()\n",
    "            line = line.split('\\t')\n",
    "            text.append(line[2])\n",
    "            sentiment.append(line[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Google News Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "vectoriser = gensim.models.KeyedVectors.load_word2vec_format('path to word2vec/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convering Sentences to word\n",
    "\n",
    "Variable \"text\" is a list of sentences which is converted to a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "for word in text:\n",
    "    x_train.append(text_to_word_sequence(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a vocabulary of all the words availabe in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15288 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "all_word = []\n",
    "for sentence in x_train:\n",
    "    all_word.extend(sentence)\n",
    "        \n",
    "all_word = list(set(all_word))\n",
    "print(len(all_word), type(all_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the words available in our dataset with the words in our word2vec model and removing all the words which are not available in our word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14028\n"
     ]
    }
   ],
   "source": [
    "vect_vocab = []\n",
    "for checker in all_word:\n",
    "    if checker in vectoriser:\n",
    "        vect_vocab.append(checker)\n",
    "print(len(vect_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all the words from our training set which are not available in our word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156060"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_xtrain = []\n",
    "for word in x_train:\n",
    "    new_xtrain.append(list(x for x in word if x in vect_vocab))\n",
    "len(new_xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing our training set by removing all the empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xtrain1 = new_xtrain[:]\n",
    "temp = []\n",
    "for x in range(len(new_xtrain)):\n",
    "    if new_xtrain[x] == []:\n",
    "        temp.append(x)\n",
    "        \n",
    "for x in reversed(temp):\n",
    "    sentiment.pop(x)\n",
    "    new_xtrain1.pop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154144, 154144)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_xtrain1), len(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the labels(integers) to binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154144, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = 5\n",
    "y_train = to_categorical(sentiment, num_class)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154144,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_xtrain1 = np.array(new_xtrain1)\n",
    "new_xtrain1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the words in our dataset to vector(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_xtrain = []\n",
    "for word in new_xtrain1:\n",
    "    vec_xtrain.append(vectoriser[word])\n",
    "vec_xtrain = np.array(vec_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154144,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_xtrain[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking average of all the words in a sentence which are available in the matrix form so that the vector of the entire sentence can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_xtrain1 = []\n",
    "def sent_vectorizer(sent):\n",
    "    sent_vec = np.zeros(300)\n",
    "    numw = 0\n",
    "    for w in sent:\n",
    "        try:\n",
    "            sent_vec = np.add(sent_vec, w)\n",
    "            numw+=1\n",
    "        except:\n",
    "            pass\n",
    "    return sent_vec / numw\n",
    "for x in vec_xtrain:\n",
    "    vec_xtrain1.append(sent_vectorizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154144, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_xtrain1 = np.array(vec_xtrain1)\n",
    "vec_xtrain1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating our data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vector, x_test_vector, y_train_vector, y_test_vector = train_test_split(vec_xtrain1, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123315, 300), (30829, 300), (123315, 5), (30829, 5))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vector.shape, x_test_vector.shape, y_train_vector.shape, y_test_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 1024)              308224    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 965,637\n",
      "Trainable params: 965,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu',input_dim=300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['categorical_accuracy', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 123315 samples, validate on 30829 samples\n",
      "Epoch 1/20\n",
      "123315/123315 [==============================] - 12s 95us/step - loss: 0.9650 - categorical_accuracy: 0.6007 - acc: 0.6007 - val_loss: 0.9010 - val_categorical_accuracy: 0.6222 - val_acc: 0.6222\n",
      "Epoch 2/20\n",
      "123315/123315 [==============================] - 11s 90us/step - loss: 0.9163 - categorical_accuracy: 0.6240 - acc: 0.6240 - val_loss: 0.9318 - val_categorical_accuracy: 0.6225 - val_acc: 0.6225\n",
      "Epoch 3/20\n",
      "123315/123315 [==============================] - 11s 91us/step - loss: 0.8982 - categorical_accuracy: 0.6380 - acc: 0.6380 - val_loss: 0.8919 - val_categorical_accuracy: 0.6410 - val_acc: 0.6410\n",
      "Epoch 4/20\n",
      "123315/123315 [==============================] - 11s 90us/step - loss: 0.8788 - categorical_accuracy: 0.6476 - acc: 0.6476 - val_loss: 0.9207 - val_categorical_accuracy: 0.6300 - val_acc: 0.6300\n",
      "Epoch 5/20\n",
      "123315/123315 [==============================] - 11s 91us/step - loss: 0.8736 - categorical_accuracy: 0.6563 - acc: 0.6563 - val_loss: 0.9069 - val_categorical_accuracy: 0.6448 - val_acc: 0.6448\n",
      "Epoch 6/20\n",
      "123315/123315 [==============================] - 11s 91us/step - loss: 0.8689 - categorical_accuracy: 0.6638 - acc: 0.6638 - val_loss: 0.9097 - val_categorical_accuracy: 0.6420 - val_acc: 0.6420\n",
      "Epoch 7/20\n",
      "123315/123315 [==============================] - 11s 92us/step - loss: 0.8557 - categorical_accuracy: 0.6708 - acc: 0.6708 - val_loss: 0.9572 - val_categorical_accuracy: 0.6427 - val_acc: 0.6427\n",
      "Epoch 8/20\n",
      "123315/123315 [==============================] - 11s 91us/step - loss: 0.8617 - categorical_accuracy: 0.6753 - acc: 0.6753 - val_loss: 0.9549 - val_categorical_accuracy: 0.6519 - val_acc: 0.6519\n",
      "Epoch 9/20\n",
      "123315/123315 [==============================] - 11s 92us/step - loss: 0.8488 - categorical_accuracy: 0.6813 - acc: 0.6813 - val_loss: 0.9834 - val_categorical_accuracy: 0.6312 - val_acc: 0.6312\n",
      "Epoch 10/20\n",
      "123315/123315 [==============================] - 11s 92us/step - loss: 0.8441 - categorical_accuracy: 0.6853 - acc: 0.6853 - val_loss: 0.9692 - val_categorical_accuracy: 0.6506 - val_acc: 0.6506\n",
      "Epoch 11/20\n",
      "123315/123315 [==============================] - 11s 92us/step - loss: 0.8376 - categorical_accuracy: 0.6899 - acc: 0.6899 - val_loss: 0.9805 - val_categorical_accuracy: 0.6514 - val_acc: 0.6514\n",
      "Epoch 12/20\n",
      "123315/123315 [==============================] - 11s 93us/step - loss: 0.8389 - categorical_accuracy: 0.6916 - acc: 0.6916 - val_loss: 0.9852 - val_categorical_accuracy: 0.6567 - val_acc: 0.6567\n",
      "Epoch 13/20\n",
      " 12256/123315 [=>............................] - ETA: 9s - loss: 0.8237 - categorical_accuracy: 0.7019 - acc: 0.7019"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_vector, y_train_vector, epochs=20, batch_size=32,validation_data=(x_test_vector,y_test_vector), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30829/30829 [==============================] - 1s 27us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9152104708129044, 0.6486100749371831, 0.6486100749371831]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_vector, y_test_vector, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x_test_vector[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_vector[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32+32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 64, 128, 256, 512, 1024, 2048]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = []\n",
    "x=16\n",
    "while x<=1024:\n",
    "    x = x*2\n",
    "    c.append(x)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 123315 samples, validate on 30829 samples\n",
      "Epoch 1/10\n",
      "123315/123315 [==============================] - 10s 83us/step - loss: 1.0546 - categorical_accuracy: 0.5624 - acc: 0.5624 - val_loss: 0.9495 - val_categorical_accuracy: 0.6016 - val_acc: 0.6016\n",
      "Epoch 2/10\n",
      "123315/123315 [==============================] - 10s 79us/step - loss: 0.9649 - categorical_accuracy: 0.5987 - acc: 0.5987 - val_loss: 0.9258 - val_categorical_accuracy: 0.6150 - val_acc: 0.6150\n",
      "Epoch 3/10\n",
      "123315/123315 [==============================] - 10s 81us/step - loss: 0.9466 - categorical_accuracy: 0.6058 - acc: 0.6058 - val_loss: 0.9286 - val_categorical_accuracy: 0.6158 - val_acc: 0.6158\n",
      "Epoch 4/10\n",
      "123315/123315 [==============================] - 10s 79us/step - loss: 0.9365 - categorical_accuracy: 0.6119 - acc: 0.6119 - val_loss: 0.9083 - val_categorical_accuracy: 0.6187 - val_acc: 0.6187\n",
      "Epoch 5/10\n",
      "123315/123315 [==============================] - 10s 79us/step - loss: 0.9285 - categorical_accuracy: 0.6131 - acc: 0.6131 - val_loss: 0.9068 - val_categorical_accuracy: 0.6213 - val_acc: 0.6213\n",
      "Epoch 6/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.9224 - categorical_accuracy: 0.6170 - acc: 0.6170 - val_loss: 0.9076 - val_categorical_accuracy: 0.6245 - val_acc: 0.6245\n",
      "Epoch 7/10\n",
      "123315/123315 [==============================] - 10s 82us/step - loss: 0.9177 - categorical_accuracy: 0.6183 - acc: 0.6183 - val_loss: 0.9021 - val_categorical_accuracy: 0.6205 - val_acc: 0.6205\n",
      "Epoch 8/10\n",
      "123315/123315 [==============================] - 10s 84us/step - loss: 0.9130 - categorical_accuracy: 0.6197 - acc: 0.6197 - val_loss: 0.9038 - val_categorical_accuracy: 0.6229 - val_acc: 0.6229\n",
      "Epoch 9/10\n",
      "123315/123315 [==============================] - 10s 82us/step - loss: 0.9115 - categorical_accuracy: 0.6207 - acc: 0.6207 - val_loss: 0.9012 - val_categorical_accuracy: 0.6252 - val_acc: 0.6252\n",
      "Epoch 10/10\n",
      "123315/123315 [==============================] - 9s 75us/step - loss: 0.9091 - categorical_accuracy: 0.6221 - acc: 0.6221 - val_loss: 0.9000 - val_categorical_accuracy: 0.6290 - val_acc: 0.6290\n",
      "30829/30829 [==============================] - 1s 26us/step\n",
      "Train on 123315 samples, validate on 30829 samples\n",
      "Epoch 1/10\n",
      "123315/123315 [==============================] - 11s 85us/step - loss: 1.0058 - categorical_accuracy: 0.5848 - acc: 0.5848 - val_loss: 0.9181 - val_categorical_accuracy: 0.6138 - val_acc: 0.6138\n",
      "Epoch 2/10\n",
      "123315/123315 [==============================] - 11s 86us/step - loss: 0.9360 - categorical_accuracy: 0.6114 - acc: 0.6114 - val_loss: 0.9050 - val_categorical_accuracy: 0.6195 - val_acc: 0.6195\n",
      "Epoch 3/10\n",
      "123315/123315 [==============================] - 11s 85us/step - loss: 0.9154 - categorical_accuracy: 0.6194 - acc: 0.6194 - val_loss: 0.8928 - val_categorical_accuracy: 0.6279 - val_acc: 0.6279\n",
      "Epoch 4/10\n",
      "123315/123315 [==============================] - 10s 85us/step - loss: 0.9027 - categorical_accuracy: 0.6240 - acc: 0.6240 - val_loss: 0.8845 - val_categorical_accuracy: 0.6327 - val_acc: 0.6327\n",
      "Epoch 5/10\n",
      "123315/123315 [==============================] - 10s 83us/step - loss: 0.8925 - categorical_accuracy: 0.6305 - acc: 0.6305 - val_loss: 0.8855 - val_categorical_accuracy: 0.6297 - val_acc: 0.6297\n",
      "Epoch 6/10\n",
      "123315/123315 [==============================] - 10s 78us/step - loss: 0.8855 - categorical_accuracy: 0.6320 - acc: 0.6320 - val_loss: 0.8800 - val_categorical_accuracy: 0.6339 - val_acc: 0.6339\n",
      "Epoch 7/10\n",
      "123315/123315 [==============================] - 10s 82us/step - loss: 0.8776 - categorical_accuracy: 0.6360 - acc: 0.6360 - val_loss: 0.8802 - val_categorical_accuracy: 0.6358 - val_acc: 0.6358\n",
      "Epoch 8/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8721 - categorical_accuracy: 0.6384 - acc: 0.6384 - val_loss: 0.8771 - val_categorical_accuracy: 0.6330 - val_acc: 0.6330\n",
      "Epoch 9/10\n",
      "123315/123315 [==============================] - 11s 86us/step - loss: 0.8681 - categorical_accuracy: 0.6408 - acc: 0.6408 - val_loss: 0.8772 - val_categorical_accuracy: 0.6376 - val_acc: 0.6376\n",
      "Epoch 10/10\n",
      "123315/123315 [==============================] - 10s 84us/step - loss: 0.8637 - categorical_accuracy: 0.6423 - acc: 0.6423 - val_loss: 0.8865 - val_categorical_accuracy: 0.6349 - val_acc: 0.6349\n",
      "30829/30829 [==============================] - 1s 31us/step\n",
      "Train on 123315 samples, validate on 30829 samples\n",
      "Epoch 1/10\n",
      "123315/123315 [==============================] - 11s 92us/step - loss: 0.9708 - categorical_accuracy: 0.5981 - acc: 0.5981 - val_loss: 0.9096 - val_categorical_accuracy: 0.6207 - val_acc: 0.6207\n",
      "Epoch 2/10\n",
      "123315/123315 [==============================] - 10s 84us/step - loss: 0.9156 - categorical_accuracy: 0.6200 - acc: 0.6200 - val_loss: 0.8915 - val_categorical_accuracy: 0.6284 - val_acc: 0.6284\n",
      "Epoch 3/10\n",
      "123315/123315 [==============================] - 10s 79us/step - loss: 0.8915 - categorical_accuracy: 0.6302 - acc: 0.6302 - val_loss: 0.8939 - val_categorical_accuracy: 0.6295 - val_acc: 0.6295\n",
      "Epoch 4/10\n",
      "123315/123315 [==============================] - 10s 82us/step - loss: 0.8760 - categorical_accuracy: 0.6391 - acc: 0.6391 - val_loss: 0.8801 - val_categorical_accuracy: 0.6335 - val_acc: 0.6335\n",
      "Epoch 5/10\n",
      "123315/123315 [==============================] - 10s 84us/step - loss: 0.8638 - categorical_accuracy: 0.6434 - acc: 0.6434 - val_loss: 0.8699 - val_categorical_accuracy: 0.6396 - val_acc: 0.6396\n",
      "Epoch 6/10\n",
      "123315/123315 [==============================] - 11s 86us/step - loss: 0.8538 - categorical_accuracy: 0.6487 - acc: 0.6487 - val_loss: 0.8751 - val_categorical_accuracy: 0.6370 - val_acc: 0.6370\n",
      "Epoch 7/10\n",
      "123315/123315 [==============================] - 10s 81us/step - loss: 0.8440 - categorical_accuracy: 0.6536 - acc: 0.6536 - val_loss: 0.8612 - val_categorical_accuracy: 0.6447 - val_acc: 0.6447\n",
      "Epoch 8/10\n",
      "123315/123315 [==============================] - 10s 79us/step - loss: 0.8388 - categorical_accuracy: 0.6561 - acc: 0.6561 - val_loss: 0.8606 - val_categorical_accuracy: 0.6471 - val_acc: 0.6471\n",
      "Epoch 9/10\n",
      "123315/123315 [==============================] - 10s 84us/step - loss: 0.8301 - categorical_accuracy: 0.6589 - acc: 0.6589 - val_loss: 0.8590 - val_categorical_accuracy: 0.6497 - val_acc: 0.6497\n",
      "Epoch 10/10\n",
      "123315/123315 [==============================] - 11s 88us/step - loss: 0.8277 - categorical_accuracy: 0.6593 - acc: 0.6593 - val_loss: 0.8610 - val_categorical_accuracy: 0.6523 - val_acc: 0.6523\n",
      "30829/30829 [==============================] - 1s 28us/step\n",
      "Train on 123315 samples, validate on 30829 samples\n",
      "Epoch 1/10\n",
      "123315/123315 [==============================] - 11s 85us/step - loss: 0.9579 - categorical_accuracy: 0.6020 - acc: 0.6020 - val_loss: 0.9222 - val_categorical_accuracy: 0.6147 - val_acc: 0.6147\n",
      "Epoch 2/10\n",
      "123315/123315 [==============================] - 10s 84us/step - loss: 0.9012 - categorical_accuracy: 0.6266 - acc: 0.6266 - val_loss: 0.8871 - val_categorical_accuracy: 0.6319 - val_acc: 0.6319\n",
      "Epoch 3/10\n",
      "123315/123315 [==============================] - 11s 92us/step - loss: 0.8770 - categorical_accuracy: 0.6380 - acc: 0.6380 - val_loss: 0.8911 - val_categorical_accuracy: 0.6301 - val_acc: 0.6301\n",
      "Epoch 4/10\n",
      "123315/123315 [==============================] - 11s 89us/step - loss: 0.8631 - categorical_accuracy: 0.6457 - acc: 0.6457 - val_loss: 0.8734 - val_categorical_accuracy: 0.6436 - val_acc: 0.6436\n",
      "Epoch 5/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8505 - categorical_accuracy: 0.6523 - acc: 0.6523 - val_loss: 0.8739 - val_categorical_accuracy: 0.6370 - val_acc: 0.6370\n",
      "Epoch 6/10\n",
      "123315/123315 [==============================] - 12s 93us/step - loss: 0.8370 - categorical_accuracy: 0.6582 - acc: 0.6582 - val_loss: 0.8574 - val_categorical_accuracy: 0.6500 - val_acc: 0.6500\n",
      "Epoch 7/10\n",
      "123315/123315 [==============================] - 11s 89us/step - loss: 0.8265 - categorical_accuracy: 0.6645 - acc: 0.6645 - val_loss: 0.8803 - val_categorical_accuracy: 0.6450 - val_acc: 0.6450\n",
      "Epoch 8/10\n",
      "123315/123315 [==============================] - 11s 88us/step - loss: 0.8197 - categorical_accuracy: 0.6688 - acc: 0.6688 - val_loss: 0.8580 - val_categorical_accuracy: 0.6500 - val_acc: 0.6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "123315/123315 [==============================] - 10s 81us/step - loss: 0.8128 - categorical_accuracy: 0.6732 - acc: 0.6732 - val_loss: 0.8787 - val_categorical_accuracy: 0.6519 - val_acc: 0.6519\n",
      "Epoch 10/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8100 - categorical_accuracy: 0.6757 - acc: 0.6757 - val_loss: 0.8773 - val_categorical_accuracy: 0.6536 - val_acc: 0.6536\n",
      "30829/30829 [==============================] - 1s 28us/step\n",
      "Train on 123315 samples, validate on 30829 samples\n",
      "Epoch 1/10\n",
      "123315/123315 [==============================] - 10s 84us/step - loss: 0.9574 - categorical_accuracy: 0.6018 - acc: 0.6018 - val_loss: 0.8998 - val_categorical_accuracy: 0.6262 - val_acc: 0.6262\n",
      "Epoch 2/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.9093 - categorical_accuracy: 0.6242 - acc: 0.6242 - val_loss: 0.8999 - val_categorical_accuracy: 0.6313 - val_acc: 0.6313\n",
      "Epoch 3/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8924 - categorical_accuracy: 0.6363 - acc: 0.6363 - val_loss: 0.8739 - val_categorical_accuracy: 0.6395 - val_acc: 0.6395\n",
      "Epoch 4/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8787 - categorical_accuracy: 0.6456 - acc: 0.6456 - val_loss: 0.8741 - val_categorical_accuracy: 0.6453 - val_acc: 0.6453\n",
      "Epoch 5/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8695 - categorical_accuracy: 0.6512 - acc: 0.6512 - val_loss: 0.8984 - val_categorical_accuracy: 0.6473 - val_acc: 0.6473\n",
      "Epoch 6/10\n",
      "123315/123315 [==============================] - 10s 79us/step - loss: 0.8579 - categorical_accuracy: 0.6585 - acc: 0.6585 - val_loss: 0.8707 - val_categorical_accuracy: 0.6469 - val_acc: 0.6469\n",
      "Epoch 7/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8554 - categorical_accuracy: 0.6645 - acc: 0.6645 - val_loss: 0.9012 - val_categorical_accuracy: 0.6505 - val_acc: 0.6505\n",
      "Epoch 8/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8489 - categorical_accuracy: 0.6695 - acc: 0.6695 - val_loss: 0.9196 - val_categorical_accuracy: 0.6430 - val_acc: 0.6430\n",
      "Epoch 9/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8492 - categorical_accuracy: 0.6735 - acc: 0.6735 - val_loss: 0.9005 - val_categorical_accuracy: 0.6504 - val_acc: 0.6504\n",
      "Epoch 10/10\n",
      "123315/123315 [==============================] - 10s 80us/step - loss: 0.8458 - categorical_accuracy: 0.6767 - acc: 0.6767 - val_loss: 0.9365 - val_categorical_accuracy: 0.6541 - val_acc: 0.6541\n",
      "30829/30829 [==============================] - 1s 28us/step\n",
      "Train on 123315 samples, validate on 30829 samples\n",
      "Epoch 1/10\n",
      "123315/123315 [==============================] - 11s 93us/step - loss: 0.9632 - categorical_accuracy: 0.6017 - acc: 0.6017 - val_loss: 0.9013 - val_categorical_accuracy: 0.6266 - val_acc: 0.6266\n",
      "Epoch 2/10\n",
      "123315/123315 [==============================] - 11s 88us/step - loss: 0.9148 - categorical_accuracy: 0.6255 - acc: 0.6255 - val_loss: 0.9063 - val_categorical_accuracy: 0.6275 - val_acc: 0.6275\n",
      "Epoch 3/10\n",
      "123315/123315 [==============================] - 11s 89us/step - loss: 0.8931 - categorical_accuracy: 0.6385 - acc: 0.6385 - val_loss: 0.9090 - val_categorical_accuracy: 0.6283 - val_acc: 0.6283\n",
      "Epoch 4/10\n",
      "123315/123315 [==============================] - 11s 90us/step - loss: 0.8817 - categorical_accuracy: 0.6489 - acc: 0.6489 - val_loss: 0.9015 - val_categorical_accuracy: 0.6447 - val_acc: 0.6447\n",
      "Epoch 5/10\n",
      "123315/123315 [==============================] - 11s 89us/step - loss: 0.8640 - categorical_accuracy: 0.6567 - acc: 0.6567 - val_loss: 0.9069 - val_categorical_accuracy: 0.6483 - val_acc: 0.6483\n",
      "Epoch 6/10\n",
      "123315/123315 [==============================] - 11s 89us/step - loss: 0.8602 - categorical_accuracy: 0.6646 - acc: 0.6646 - val_loss: 0.9748 - val_categorical_accuracy: 0.6307 - val_acc: 0.6307\n",
      "Epoch 7/10\n",
      "123315/123315 [==============================] - 11s 89us/step - loss: 0.8536 - categorical_accuracy: 0.6718 - acc: 0.6718 - val_loss: 0.9135 - val_categorical_accuracy: 0.6426 - val_acc: 0.6426\n",
      "Epoch 8/10\n",
      "123315/123315 [==============================] - 11s 88us/step - loss: 0.8370 - categorical_accuracy: 0.6785 - acc: 0.6785 - val_loss: 0.9243 - val_categorical_accuracy: 0.6532 - val_acc: 0.6532\n",
      "Epoch 9/10\n",
      "123315/123315 [==============================] - 11s 88us/step - loss: 0.8379 - categorical_accuracy: 0.6848 - acc: 0.6848 - val_loss: 1.0069 - val_categorical_accuracy: 0.6422 - val_acc: 0.6422\n",
      "Epoch 10/10\n",
      "123315/123315 [==============================] - 11s 88us/step - loss: 0.8380 - categorical_accuracy: 0.6896 - acc: 0.6896 - val_loss: 0.9232 - val_categorical_accuracy: 0.6547 - val_acc: 0.6547\n",
      "30829/30829 [==============================] - 1s 29us/step\n",
      "Train on 123315 samples, validate on 30829 samples\n",
      "Epoch 1/10\n",
      "123315/123315 [==============================] - 18s 142us/step - loss: 0.9720 - categorical_accuracy: 0.5982 - acc: 0.5982 - val_loss: 0.9215 - val_categorical_accuracy: 0.6231 - val_acc: 0.6231\n",
      "Epoch 2/10\n",
      "123315/123315 [==============================] - 17s 134us/step - loss: 0.9281 - categorical_accuracy: 0.6214 - acc: 0.6214 - val_loss: 0.9306 - val_categorical_accuracy: 0.6284 - val_acc: 0.6284\n",
      "Epoch 3/10\n",
      "123315/123315 [==============================] - 17s 134us/step - loss: 0.9148 - categorical_accuracy: 0.6344 - acc: 0.6344 - val_loss: 0.9105 - val_categorical_accuracy: 0.6348 - val_acc: 0.6348\n",
      "Epoch 4/10\n",
      "123315/123315 [==============================] - 17s 134us/step - loss: 0.9032 - categorical_accuracy: 0.6444 - acc: 0.6444 - val_loss: 0.9388 - val_categorical_accuracy: 0.6292 - val_acc: 0.6292\n",
      "Epoch 5/10\n",
      "123315/123315 [==============================] - 17s 134us/step - loss: 0.9030 - categorical_accuracy: 0.6537 - acc: 0.6537 - val_loss: 0.9842 - val_categorical_accuracy: 0.6324 - val_acc: 0.6324\n",
      "Epoch 6/10\n",
      "123315/123315 [==============================] - 17s 134us/step - loss: 0.9026 - categorical_accuracy: 0.6610 - acc: 0.6610 - val_loss: 1.0065 - val_categorical_accuracy: 0.6318 - val_acc: 0.6318\n",
      "Epoch 7/10\n",
      "123315/123315 [==============================] - 17s 136us/step - loss: 0.9009 - categorical_accuracy: 0.6686 - acc: 0.6686 - val_loss: 1.0010 - val_categorical_accuracy: 0.6415 - val_acc: 0.6415\n",
      "Epoch 8/10\n",
      "123315/123315 [==============================] - 17s 136us/step - loss: 0.8916 - categorical_accuracy: 0.6754 - acc: 0.6754 - val_loss: 0.9639 - val_categorical_accuracy: 0.6542 - val_acc: 0.6542\n",
      "Epoch 9/10\n",
      "123315/123315 [==============================] - 17s 135us/step - loss: 0.8729 - categorical_accuracy: 0.6810 - acc: 0.6810 - val_loss: 1.0164 - val_categorical_accuracy: 0.6220 - val_acc: 0.6220\n",
      "Epoch 10/10\n",
      "123315/123315 [==============================] - 17s 135us/step - loss: 0.8781 - categorical_accuracy: 0.6850 - acc: 0.6850 - val_loss: 1.0625 - val_categorical_accuracy: 0.6440 - val_acc: 0.6440\n",
      "30829/30829 [==============================] - 1s 29us/step\n"
     ]
    }
   ],
   "source": [
    "acc = 0.0\n",
    "for i in c:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(i, activation='relu',input_dim=300))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(i//2, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(i//4, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "#     model.summary()\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['categorical_accuracy', 'accuracy'])\n",
    "    model.fit(x_train_vector, y_train_vector, epochs=10, batch_size=32,validation_data=(x_test_vector,y_test_vector), verbose=1)\n",
    "    a = model.evaluate(x_test_vector, y_test_vector, batch_size=32)\n",
    "    if a[1] > acc:\n",
    "        acc = a[1]\n",
    "        loss = a[0]\n",
    "        inter = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6546757922831757, 0.9232274577934645, 1024)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, loss, inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
